"""
ë¬¸ì„œ ì—…ë¡œë“œ API
ì—­í• : í•™ìŠµ ë¬¸ì„œ(PDF/TXT/DOCX) ì—…ë¡œë“œ, í…ìŠ¤íŠ¸ ì¶”ì¶œ, ì²­í¬ ë¶„í• 

ğŸ“‹ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¥¼ ìœ„í•œ ì‚¬ìš© ê°€ì´ë“œ
==========================================

1. ë¬¸ì„œ ì—…ë¡œë“œ: POST /documents
   - multipart/form-dataë¡œ íŒŒì¼ ì „ì†¡
   - ì‘ë‹µìœ¼ë¡œ document_id ë°›ìŒ
   - âœ¨ Google Document AIë¡œ ê³ í’ˆì§ˆ OCR ì²˜ë¦¬

2. ìƒíƒœ í™•ì¸: GET /documents/{document_id}
   - statusê°€ "ready"ê°€ ë  ë•Œê¹Œì§€ í´ë§

3. í”„ë¦¬ë·° í™•ì¸: GET /documents/{document_id}/preview
   - ì—…ë¡œë“œ í™•ì¸ ëª¨ë‹¬ì— í‘œì‹œí•  í…ìŠ¤íŠ¸

4. ì²­í¬ ì¡°íšŒ: GET /documents/{document_id}/chunks
   - ì„¸ì…˜ ì‹œì‘ ì‹œ chunk_id ì„ íƒìš©
"""

from fastapi import APIRouter, HTTPException, status, UploadFile, File, Form, Depends
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from datetime import datetime
import uuid
import os
import tempfile

from app.db.session import get_db
from app.db.models import User, RAGDocument, TextChunk
from app.core.auth import get_current_user
from app.services.document_ai import get_document_ai_service

router = APIRouter(prefix="/documents", tags=["ğŸ“„ Document Management"])


# ============================================================
# Request/Response Models - í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì ì°¸ê³ ìš© ìƒì„¸ ì„¤ëª…
# ============================================================

class DocumentUploadResponse(BaseModel):
    """
    ë¬¸ì„œ ì—…ë¡œë“œ ì‘ë‹µ
    
    Example:
    ```json
    {
        "document_id": "doc_abc123",
        "status": "processing",
        "message": "ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.",
        "meta": {
            "filename": "ì¶˜í–¥ì „.pdf",
            "file_size": 102400,
            "mime_type": "application/pdf"
        }
    }
    ```
    """
    document_id: str = Field(..., description="ë¬¸ì„œ ê³ ìœ  ID. ì´í›„ ëª¨ë“  API í˜¸ì¶œì— ì‚¬ìš©", example="doc_abc123")
    status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ: processing(ì²˜ë¦¬ì¤‘) | ready(ì™„ë£Œ) | failed(ì‹¤íŒ¨)", example="processing")
    message: str = Field(..., description="ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•  ë©”ì‹œì§€", example="ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    meta: Dict[str, Any] = Field(default_factory=dict, description="íŒŒì¼ ë©”íƒ€ë°ì´í„°")


class DocumentStatusResponse(BaseModel):
    """
    ë¬¸ì„œ ìƒíƒœ ì¡°íšŒ ì‘ë‹µ
    
    - statusê°€ "ready"ê°€ ë˜ë©´ preview/chunks ì¡°íšŒ ê°€ëŠ¥
    - "failed"ì¸ ê²½ìš° error_message í™•ì¸
    
    Example:
    ```json
    {
        "document_id": "doc_abc123",
        "status": "ready",
        "title": "ì¶˜í–¥ì „",
        "total_chunks": 15,
        "total_chars": 12500,
        "created_at": "2026-02-06T12:00:00Z"
    }
    ```
    """
    document_id: str = Field(..., description="ë¬¸ì„œ ê³ ìœ  ID")
    status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ", example="ready")
    title: Optional[str] = Field(None, description="ë¬¸ì„œ ì œëª©")
    total_chunks: int = Field(0, description="ë¶„í• ëœ ì²­í¬ ìˆ˜")
    total_chars: int = Field(0, description="ì´ ë¬¸ì ìˆ˜")
    created_at: str = Field(..., description="ìƒì„± ì‹œê° (ISO 8601)")
    error_message: Optional[str] = Field(None, description="ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€")


class DocumentPreviewResponse(BaseModel):
    """
    ë¬¸ì„œ í”„ë¦¬ë·° ì‘ë‹µ - ì—…ë¡œë“œ í™•ì¸ ëª¨ë‹¬ìš©
    
    - ì•/ì¤‘ê°„/ë’·ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸° ì œê³µ
    - ì‚¬ìš©ìê°€ ì˜¬ë°”ë¥¸ ë¬¸ì„œì¸ì§€ í™•ì¸í•˜ëŠ” ìš©ë„
    
    Example:
    ```json
    {
        "document_id": "doc_abc123",
        "title": "ì¶˜í–¥ì „",
        "preview": {
            "beginning": "ë‚¨ì› ê³ ì„ì— ì´ë„ë ¹ì´ë¼ í•˜ëŠ” ì–‘ë°˜ì´...",
            "middle": "ì¶˜í–¥ì´ ê·¸ë„¤ë¥¼ íƒ€ëŠ” ëª¨ìŠµì„ ë³´ê³ ...",
            "end": "ì´ë„ë ¹ê³¼ ì¶˜í–¥ì€ ë°±ë…„í•´ë¡œí•˜ì˜€ë‹¤."
        },
        "total_chars": 12500
    }
    ```
    """
    document_id: str
    title: Optional[str]
    preview: Dict[str, str] = Field(..., description="ì•/ì¤‘ê°„/ë’·ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°")
    total_chars: int


class ChunkItem(BaseModel):
    """
    ì²­í¬ ì •ë³´ - ì„¸ì…˜ ì‹œì‘ ì‹œ chunk_id ì„ íƒì— ì‚¬ìš©
    
    anchor: ë¬¸ì„œ ë‚´ ìœ„ì¹˜ ì •ë³´ (ê·¼ê±° í‘œì‹œìš©)
    """
    chunk_id: str = Field(..., description="ì²­í¬ ê³ ìœ  ID", example="chunk_001")
    sequence: int = Field(..., description="ìˆœì„œ (1ë¶€í„° ì‹œì‘)", example=1)
    text: str = Field(..., description="ì²­í¬ í…ìŠ¤íŠ¸ ë‚´ìš©")
    anchor: Dict[str, Any] = Field(..., description="ìœ„ì¹˜ ì •ë³´ {page, paragraph, char_start, char_end}")


class DocumentChunksResponse(BaseModel):
    """
    ë¬¸ì„œ ì²­í¬ ëª©ë¡ ì‘ë‹µ
    
    - ì„¸ì…˜ ì‹œì‘ ì‹œ work_id/chunk_id ì„ íƒì— ì‚¬ìš©
    - ê° ì²­í¬ì— anchor ì •ë³´ í¬í•¨ (ê·¼ê±° ìœ„ì¹˜ í‘œì‹œìš©)
    
    Example:
    ```json
    {
        "document_id": "doc_abc123",
        "chunks": [
            {
                "chunk_id": "chunk_001",
                "sequence": 1,
                "text": "ë‚¨ì› ê³ ì„ì— ì´ë„ë ¹ì´ë¼ í•˜ëŠ” ì–‘ë°˜ì´...",
                "anchor": {"page": 1, "paragraph": 1, "char_start": 0, "char_end": 150}
            }
        ],
        "total_chunks": 15
    }
    ```
    """
    document_id: str
    chunks: List[ChunkItem]
    total_chunks: int


# ============================================================
# í—¬í¼ í•¨ìˆ˜
# ============================================================




def split_into_chunks(text: str, chunk_size: int = 500) -> List[Dict]:
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    chunks = []
    
    # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¨¼ì € ë¶„ë¦¬
    paragraphs = text.split("\n\n")
    
    current_chunk = ""
    current_start = 0
    sequence = 1
    
    for para in paragraphs:
        if len(current_chunk) + len(para) > chunk_size and current_chunk:
            chunks.append({
                "sequence": sequence,
                "text": current_chunk.strip(),
                "anchor": {
                    "char_start": current_start,
                    "char_end": current_start + len(current_chunk),
                    "paragraph": sequence
                }
            })
            sequence += 1
            current_start += len(current_chunk)
            current_chunk = para + "\n\n"
        else:
            current_chunk += para + "\n\n"
    
    # ë§ˆì§€ë§‰ ì²­í¬
    if current_chunk.strip():
        chunks.append({
            "sequence": sequence,
            "text": current_chunk.strip(),
            "anchor": {
                "char_start": current_start,
                "char_end": current_start + len(current_chunk),
                "paragraph": sequence
            }
        })
    
    return chunks


# ============================================================
# API Endpoints
# ============================================================

@router.post(
    "",
    response_model=DocumentUploadResponse,
    summary="ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ",
    description="""
    í•™ìŠµìš© ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    ## ì§€ì› í˜•ì‹
    - **PDF**: .pdf
    - **í…ìŠ¤íŠ¸**: .txt
    - **Word**: .docx
    
    ## ì‚¬ìš© ì˜ˆì‹œ (JavaScript)
    ```javascript
    const formData = new FormData();
    formData.append('file', fileInput.files[0]);
    formData.append('title', 'ì¶˜í–¥ì „');
    
    const response = await fetch('/documents', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${token}` },
        body: formData
    });
    const data = await response.json();
    console.log(data.document_id); // ì´ IDë¡œ ì´í›„ API í˜¸ì¶œ
    ```
    
    ## ì£¼ì˜ì‚¬í•­
    - ìµœëŒ€ íŒŒì¼ í¬ê¸°: 10MB
    - ì—…ë¡œë“œ í›„ ì²˜ë¦¬ì— ìˆ˜ ì´ˆ ì†Œìš”ë  ìˆ˜ ìˆìŒ
    - statusê°€ "ready"ê°€ ë  ë•Œê¹Œì§€ í´ë§ í•„ìš”
    """
)
async def upload_document(
    file: UploadFile = File(..., description="ì—…ë¡œë“œí•  ë¬¸ì„œ íŒŒì¼ (PDF/TXT/DOCX)"),
    title: Optional[str] = Form(None, description="ë¬¸ì„œ ì œëª© (ìƒëµ ì‹œ íŒŒì¼ëª… ì‚¬ìš©)"),
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ë¬¸ì„œ ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
    
    1. íŒŒì¼ì„ ì„ì‹œ ì €ì¥
    2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
    3. ì²­í¬ë¡œ ë¶„í• 
    4. DBì— ì €ì¥
    """
    
    # íŒŒì¼ í¬ê¸° ì²´í¬ (10MB)
    MAX_SIZE = 10 * 1024 * 1024
    content = await file.read()
    if len(content) > MAX_SIZE:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail="íŒŒì¼ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤"
        )
    
    # ì„ì‹œ íŒŒì¼ ì €ì¥ (Cloud Runì—ì„œëŠ” /tmp ì‚¬ìš©)
    temp_dir = tempfile.gettempdir()
    temp_path = os.path.join(temp_dir, f"{uuid.uuid4()}_{file.filename}")
    
    try:
        with open(temp_path, "wb") as f:
            f.write(content)
        
        # Document AI ì„œë¹„ìŠ¤ë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        # (ì„œë¹„ìŠ¤ ë‚´ë¶€ì—ì„œ pypdf fallback ì²˜ë¦¬ í¬í•¨)
        doc_service = get_document_ai_service()
        result = await doc_service.process_document(
            file_path=temp_path,
            mime_type=file.content_type or "application/pdf"
        )
        extracted_text = result["text"]
        
        # ì²­í¬ ë¶„í• 
        chunks = split_into_chunks(extracted_text)
        
        # ë¬¸ì„œ ID ìƒì„±
        doc_id = f"doc_{uuid.uuid4().hex[:12]}"
        doc_title = title or os.path.splitext(file.filename)[0]
        
        # RAGDocument ì €ì¥
        doc = RAGDocument(
            doc_id=doc_id,
            doc_type="uploaded",
            content=extracted_text,
            usage_stages=["LEARNING"],
            priority=5
        )
        db.add(doc)
        
        # TextChunk ì €ì¥
        for chunk_data in chunks:
            chunk = TextChunk(
                chunk_id=f"{doc_id}_chunk_{chunk_data['sequence']:03d}",
                work_id=doc_id,  # ë¬¸ì„œ IDë¥¼ work_idë¡œ ì‚¬ìš©
                sequence=chunk_data["sequence"],
                chunk_type="paragraph",
                content=chunk_data["text"],
                tags=chunk_data["anchor"]
            )
            db.add(chunk)
        
        await db.commit()
        
        return DocumentUploadResponse(
            document_id=doc_id,
            status="ready",
            message="ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
            meta={
                "filename": file.filename,
                "file_size": len(content),
                "mime_type": file.content_type,
                "total_chars": len(extracted_text),
                "total_chunks": len(chunks),
                "source": result.get("source", "unknown")
            }
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_path):
            os.remove(temp_path)


@router.get(
    "/{document_id}",
    response_model=DocumentStatusResponse,
    summary="ğŸ“‹ ë¬¸ì„œ ìƒíƒœ ì¡°íšŒ",
    description="""
    ì—…ë¡œë“œëœ ë¬¸ì„œì˜ ì²˜ë¦¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ## ìƒíƒœ ê°’
    - `processing`: ì²˜ë¦¬ ì¤‘ (í´ë§ ê³„ì†)
    - `ready`: ì™„ë£Œ (preview/chunks ì¡°íšŒ ê°€ëŠ¥)
    - `failed`: ì‹¤íŒ¨ (error_message í™•ì¸)
    
    ## ì‚¬ìš© ì˜ˆì‹œ (JavaScript)
    ```javascript
    // í´ë§ ì˜ˆì‹œ
    const checkStatus = async (docId) => {
        const res = await fetch(`/documents/${docId}`, {
            headers: { 'Authorization': `Bearer ${token}` }
        });
        const data = await res.json();
        
        if (data.status === 'ready') {
            // í”„ë¦¬ë·° í‘œì‹œ
            showPreview(docId);
        } else if (data.status === 'processing') {
            // 2ì´ˆ í›„ ì¬ì‹œë„
            setTimeout(() => checkStatus(docId), 2000);
        } else {
            // ì—ëŸ¬ ì²˜ë¦¬
            showError(data.error_message);
        }
    };
    ```
    """
)
async def get_document_status(
    document_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ë¬¸ì„œ ìƒíƒœ ì¡°íšŒ"""
    
    # ë¬¸ì„œ ì¡°íšŒ
    stmt = select(RAGDocument).where(RAGDocument.doc_id == document_id)
    result = await db.execute(stmt)
    doc = result.scalar_one_or_none()
    
    if not doc:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
        )
    
    # ì²­í¬ ìˆ˜ ì¡°íšŒ
    chunk_stmt = select(TextChunk).where(TextChunk.work_id == document_id)
    chunk_result = await db.execute(chunk_stmt)
    chunks = chunk_result.scalars().all()
    
    return DocumentStatusResponse(
        document_id=document_id,
        status="ready",
        title=document_id,  # ì‹¤ì œë¡œëŠ” ë³„ë„ title í•„ë“œ í•„ìš”
        total_chunks=len(chunks),
        total_chars=len(doc.content) if doc.content else 0,
        created_at=doc.created_at.isoformat() if doc.created_at else datetime.now().isoformat()
    )


@router.get(
    "/{document_id}/preview",
    response_model=DocumentPreviewResponse,
    summary="ğŸ‘ï¸ ë¬¸ì„œ í”„ë¦¬ë·° ì¡°íšŒ",
    description="""
    ë¬¸ì„œì˜ ì•/ì¤‘ê°„/ë’·ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    ## ìš©ë„
    - ì—…ë¡œë“œ í™•ì¸ ëª¨ë‹¬ì—ì„œ ì‚¬ìš©ìê°€ ì˜¬ë°”ë¥¸ ë¬¸ì„œì¸ì§€ í™•ì¸
    - ê° ë¶€ë¶„ ìµœëŒ€ 200ì
    
    ## ì‚¬ìš© ì˜ˆì‹œ (JavaScript)
    ```javascript
    const res = await fetch(`/documents/${docId}/preview`, {
        headers: { 'Authorization': `Bearer ${token}` }
    });
    const { preview } = await res.json();
    
    document.getElementById('previewBegin').innerText = preview.beginning;
    document.getElementById('previewMiddle').innerText = preview.middle;
    document.getElementById('previewEnd').innerText = preview.end;
    ```
    """
)
async def get_document_preview(
    document_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ë¬¸ì„œ í”„ë¦¬ë·° ì¡°íšŒ"""
    
    stmt = select(RAGDocument).where(RAGDocument.doc_id == document_id)
    result = await db.execute(stmt)
    doc = result.scalar_one_or_none()
    
    if not doc:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
        )
    
    content = doc.content or ""
    total_len = len(content)
    
    # ì•/ì¤‘ê°„/ë’¤ ê° 200ì
    preview_len = 200
    
    preview = {
        "beginning": content[:preview_len] + ("..." if total_len > preview_len else ""),
        "middle": "",
        "end": ""
    }
    
    if total_len > preview_len * 2:
        mid_start = (total_len - preview_len) // 2
        preview["middle"] = "..." + content[mid_start:mid_start + preview_len] + "..."
    
    if total_len > preview_len:
        preview["end"] = "..." + content[-preview_len:]
    
    return DocumentPreviewResponse(
        document_id=document_id,
        title=document_id,
        preview=preview,
        total_chars=total_len
    )


@router.get(
    "/{document_id}/chunks",
    response_model=DocumentChunksResponse,
    summary="ğŸ“‘ ë¬¸ì„œ ì²­í¬ ëª©ë¡ ì¡°íšŒ",
    description="""
    ë¬¸ì„œê°€ ë¶„í• ëœ ì²­í¬ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ## ìš©ë„
    - ì„¸ì…˜ ì‹œì‘ ì‹œ í•™ìŠµí•  chunk_id ì„ íƒ
    - ê·¼ê±° í‘œì‹œë¥¼ ìœ„í•œ anchor ì •ë³´ í¬í•¨
    
    ## anchor êµ¬ì¡°
    ```json
    {
        "char_start": 0,      // ì‹œì‘ ë¬¸ì ìœ„ì¹˜
        "char_end": 150,      // ë ë¬¸ì ìœ„ì¹˜
        "paragraph": 1        // ë¬¸ë‹¨ ë²ˆí˜¸
    }
    ```
    
    ## ì‚¬ìš© ì˜ˆì‹œ (JavaScript)
    ```javascript
    const res = await fetch(`/documents/${docId}/chunks`, {
        headers: { 'Authorization': `Bearer ${token}` }
    });
    const { chunks } = await res.json();
    
    // ì²­í¬ ì„ íƒ UI ë Œë”ë§
    chunks.forEach(chunk => {
        addChunkOption(chunk.chunk_id, chunk.text.slice(0, 50) + '...');
    });
    ```
    """
)
async def get_document_chunks(
    document_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ë¬¸ì„œ ì²­í¬ ëª©ë¡ ì¡°íšŒ"""
    
    stmt = select(TextChunk).where(TextChunk.work_id == document_id).order_by(TextChunk.sequence)
    result = await db.execute(stmt)
    chunks = result.scalars().all()
    
    if not chunks:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"ë¬¸ì„œ ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
        )
    
    chunk_items = [
        ChunkItem(
            chunk_id=chunk.chunk_id,
            sequence=chunk.sequence,
            text=chunk.content,
            anchor=chunk.tags if chunk.tags else {"paragraph": chunk.sequence}
        )
        for chunk in chunks
    ]
    
    return DocumentChunksResponse(
        document_id=document_id,
        chunks=chunk_items,
        total_chunks=len(chunk_items)
    )


@router.get(
    "",
    summary="ğŸ“š ë‚´ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ",
    description="""
    í˜„ì¬ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ## ì‚¬ìš© ì˜ˆì‹œ (JavaScript)
    ```javascript
    const res = await fetch('/documents', {
        headers: { 'Authorization': `Bearer ${token}` }
    });
    const { documents } = await res.json();
    
    documents.forEach(doc => {
        console.log(doc.document_id, doc.title);
    });
    ```
    """
)
async def list_documents(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """ë‚´ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
    
    # í˜„ì¬ëŠ” ëª¨ë“  ë¬¸ì„œ ë°˜í™˜ (ì¶”í›„ user_id í•„í„° ì¶”ê°€)
    stmt = select(RAGDocument).where(RAGDocument.doc_type == "uploaded")
    result = await db.execute(stmt)
    docs = result.scalars().all()
    
    return {
        "documents": [
            {
                "document_id": doc.doc_id,
                "title": doc.doc_id,
                "status": "ready",
                "total_chars": len(doc.content) if doc.content else 0,
                "created_at": doc.created_at.isoformat() if doc.created_at else None
            }
            for doc in docs
        ],
        "total": len(docs)
    }
