# 비판적 독해 AI 시스템 - Product Requirements Document

## 1. 제품 개요

### 1.1 목적
- [ ] 사용자의 비판적 독해 능력 향상을 위한 AI 기반 질문 생성 시스템 구축
- [ ] 텍스트 이해도를 단계적으로 심화시키는 소크라테스식 대화 엔진 개발
- [ ] 답을 제공하지 않고 사용자 스스로 발견하게 유도하는 교육 시스템 구현

### 1.2 핵심 가치
- [ ] 정답 제공이 아닌 사고 과정의 촉진
- [ ] 텍스트 앵커링을 통한 근거 기반 독해 습관 형성
- [ ] 논리 구조 분석 능력의 점진적 발달

---

## 2. 핵심 기능 요구사항

### 2.1 질문 생성 엔진

#### 2.1.1 QAR 기반 질문 유형 분류
- [ ] **바로 거기(Right There)**: 명시적 정보 확인 질문 생성
- [ ] **생각하고 찾기(Think and Search)**: 다중 문장 정보 통합 질문 생성
- [ ] **저자와 내 생각(Author and Me)**: 배경지식 결합형 질문 생성
- [ ] **내 힘으로(On My Own)**: 확장적 사고 유도 질문 생성
- [ ] 사용자 수준에 따라 질문 유형 비율 자동 조절

#### 2.1.2 블룸의 분류학 기반 난이도 설계
- [ ] **분석(Analyze)**: 구조 파악 질문 ("이 문단이 전체 주장 중 어떤 논리적 단계를 담당하고 있나요?")
- [ ] **평가(Evaluate)**: 비판적 검토 질문 ("저자가 제시한 근거가 주장을 뒷받침하기에 충분한가요?")
- [ ] **창조(Create)**: 가설 및 적용 질문 ("만약 저자의 전제 A가 거짓이라면, 결론 B는 어떻게 바뀌어야 할까요?")
- [ ] 하위 단계(기억/이해)는 초기 평가용으로만 제한적 사용

#### 2.1.3 사고 루틴(Thinking Routines) 통합
- [ ] **See-Think-Wonder** 패턴 구현
  - "이 문장에서 무엇이 보이나요? (사실)"
  - "그것이 무엇을 의미한다고 생각하나요? (해석)"
  - "더 궁금한 점은 무엇인가요? (확장)"
- [ ] **Claim-Support-Question** 패턴 구현
  - 주장 파악 → 근거 분석 → 논리적 의문점 도출
- [ ] **What makes you say that?** 자동 생성
  - 사용자 답변 시 근거 요구 질문 즉시 생성

### 2.2 논리 구조 분석 엔진

#### 2.2.1 툴민 모델 기반 텍스트 분해
- [ ] **데이터(Data)** 자동 추출
- [ ] **주장(Claim)** 식별
- [ ] **영장(Warrant)** 분석 - 논리적 연결 고리 탐지
- [ ] **보강(Backing)** 평가
- [ ] **반박(Rebuttal)** 가능성 예측
- [ ] 논리적 비약 지점 자동 탐지 및 질문 생성

#### 2.2.2 생략된 삼단논법 찾기
- [ ] 전제 생략 패턴 인식
- [ ] 숨겨진 전제 추론 질문 생성
- [ ] "저자는 B가 왜 C라고 당연하게 생각하는 것일까요?" 유형 자동화

#### 2.2.3 반증 사례 제시 로직
- [ ] 논리적 허점 탐지 알고리즘
- [ ] 직접 알려주지 않고 질문으로 유도
- [ ] "만약 Z 같은 예외가 있다면 이 논리는 어떻게 보완되어야 할까요?" 생성

### 2.3 소크라테스식 문답 시스템

#### 2.3.1 전제 확인 질문
- [ ] "방금 말씀하신 답변은 어떤 가정을 바탕으로 하고 있나요?" 자동 생성
- [ ] 사용자 답변에서 암묵적 전제 추출

#### 2.3.2 증거 탐구 질문
- [ ] "그렇게 생각하게 된 구체적인 문구를 본문에서 찾을 수 있을까요?" 요구
- [ ] 텍스트 앵커링 강제 메커니즘

#### 2.3.3 관점 전환 질문
- [ ] "만약 저자와 반대되는 입장이라면 이 문장을 어떻게 반박할까요?" 생성
- [ ] 다중 관점 사고 유도

#### 2.3.4 결과 및 함축 질문
- [ ] "사용자님의 해석대로라면, 다음에 이어질 내용은 무엇이 되어야 논리적일까요?" 제시
- [ ] 논리적 일관성 검증 유도

### 2.4 수사학적 분석 기능

#### 2.4.1 아리스토텔레스 수사학 3요소 분석
- [ ] **로고스(Logos)**: 논리적 오류 탐지 질문
- [ ] **에토스(Ethos)**: 저자 신뢰성 검토 질문
- [ ] **파토스(Pathos)**: 감정적 호소 분석 질문
- [ ] "논리가 부족한 부분을 감정적 호소로 덮으려 하고 있지는 않나요?" 자동 생성

#### 2.4.2 논리적 오류 분석
- [ ] 24가지 논리적 오류 패턴 데이터베이스 구축
- [ ] 성급한 일반화 탐지
- [ ] 인신공격 패턴 인식
- [ ] 권위에의 호소 분석
- [ ] 중립적 질문으로 사용자 스스로 발견하게 유도

### 2.5 다양한 독해 전략 모듈

#### 2.5.1 QtA (Questioning the Author)
- [ ] 저자를 불완전한 소통가로 가정
- [ ] 텍스트의 모호한 부분 자동 탐지
- [ ] "저자가 이 문장을 더 쉽게 썼다면 어떻게 표현했을까요?" 생성

#### 2.5.2 DR-TA (예측-검증 사이클)
- [ ] 텍스트 단계별 노출 기능
- [ ] 예측 질문 생성 ("이 소제목만 봤을 때, 저자는 다음에 어떤 통계 자료를 제시할 것 같나요?")
- [ ] 예측 vs 실제 비교 피드백

#### 2.5.3 여섯 색깔 모자 기법
- [ ] **하얀 모자(객관)**: 팩트만 나열하기
- [ ] **검은 모자(부정)**: 논리의 실패 가능성 탐색
- [ ] **노란 모자(긍정)**: 최선의 이익 도출
- [ ] **초록 모자(창의)**: 대안 제시
- [ ] 모드 전환 기능 제공

#### 2.5.4 SQ4R 통합
- [ ] Survey → Question → Read → Reflect → Recite → Review 단계별 질문 생성
- [ ] Reflect 단계에서 기존 지식 연결 질문 ("지난주에 학습한 효소 반응 원리와 어떤 점에서 유사한가요?")

---

## 3. 스캐폴딩 및 난이도 조절 시스템

### 3.1 근접발달영역(ZPD) 기반 동적 조절

#### 3.1.1 Fading 메커니즘
- [ ] 사용자 답변 정확도 실시간 측정
- [ ] 정확도 높을수록 힌트 수준 감소
- [ ] 질문 구체성 동적 조절 알고리즘

#### 3.1.2 Hints & Cues 시스템
- [ ] 답변 실패 시 정답 제공 금지
- [ ] "첫 번째 문단의 세 번째 줄을 다시 읽어보면 힌트가 있을 거예요" 유형 생성
- [ ] 3단계 힌트 시스템 (위치 힌트 → 키워드 힌트 → 논리 구조 힌트)

### 3.2 상호적 교수법 4단계

- [ ] **예측하기**: "이 소제목 다음에 어떤 논리가 이어질 것으로 예상되나요?"
- [ ] **질문하기**: "이 문단에서 가장 중요한 정보에 대해 스스로 질문을 만든다면?"
- [ ] **명료화하기**: "이 문맥에서 'X'라는 단어는 흔히 아는 뜻과 다르게 쓰인 것 같은데, 어떻게 정의할 수 있을까요?"
- [ ] **요약하기**: "지금까지의 논리를 한 문장으로 압축해 볼까요?"

---

## 4. 평가 및 피드백 시스템

### 4.1 폴-엘더 8요소 기반 평가

- [ ] **명료성(Clarity)**: "구체적인 예시를 들어 다시 설명해 줄 수 있나요?" 요청
- [ ] **정확성(Accuracy)**: 본문 정보와 일치 여부 검증
- [ ] **정밀성(Precision)**: 구체성 수준 측정
- [ ] **관련성(Relevance)**: 질문과의 연관성 평가
- [ ] **깊이(Depth)**: 표면적 vs 심층적 이해 판단
- [ ] **폭(Breadth)**: 다각적 관점 고려 여부
- [ ] **논리성(Logicalness)**: "앞서 하신 말씀과 지금 답변이 서로 모순되지 않나요?" 검증
- [ ] **공정성(Fairness)**: 편향 탐지

### 4.2 개념도 구성 지원

- [ ] 사용자 답변 기반 실시간 지식 맵 생성
- [ ] 노드(개념)와 링크(관계) 시각화
- [ ] 연결 끊긴 부분 탐지 및 질문 생성
- [ ] "'A'와 'C'는 연결되지만 'B'가 빠져 있습니다. 'B'는 이 구조에서 어떤 다리 역할을 하나요?"

### 4.3 킨치 구성-통합 모델 적용

- [ ] **Textbase**: 문장 간 표면적 연결 파악 질문
- [ ] **Situation Model**: 시뮬레이션/이미지화 유도 질문
- [ ] "글의 내용을 머릿속으로 그림을 그린다면, A와 B는 어떤 위치 관계에 있나요?"

---

## 5. LLM 시스템 프롬프트 설계

### 5.1 핵심 페르소나 규칙

- [ ] **정답 제공 금지**: 사용자가 틀려도 즉시 교정하지 말 것
- [ ] **역질문 의무화**: "그렇게 생각하신 이유가 본문의 어느 부분에 있나요?" 항상 요구
- [ ] **텍스트 앵커링 강제**: 모든 질문은 본문의 특정 구절/논리 구조에 근거
- [ ] **점진적 힌트 제공**: 직접적인 답 대신 논리적 징검다리 제시
- [ ] **중립성 유지**: 민감한 주제(82년생 김지영, 정치적 이슈)에서 가치관 강요 금지
- [ ] **형식 논리 중심**: "저자가 이러한 서술 방식을 택한 의도는 무엇일까요?"

### 5.2 질문 생성 우선순위

1. [ ] 소크라테스식 역질문 (사용자 답변에 대한 근거 요구)
2. [ ] 논리 구조 허점 탐지 질문 (툴민 모델 기반)
3. [ ] 관점 전환 질문 (여섯 색깔 모자, 반대 입장)
4. [ ] 예측-검증 질문 (DR-TA)
5. [ ] 심화 분석 질문 (블룸의 상위 단계)

### 5.3 금지 사항

- [ ] 사용자 답변에 대한 직접적 평가 ("맞습니다", "틀렸습니다") 금지
- [ ] 본문 내용의 요약 제공 금지
- [ ] 저자의 의도 단정적 설명 금지
- [ ] 정치적/윤리적 입장 강요 금지

---

## 6. 텍스트 처리 파이프라인

### 6.1 전처리 단계

- [ ] 텍스트 구조 분석 (문단, 소제목, 인용구 구분)
- [ ] 핵심 용어(Keywords) 자동 추출
- [ ] 논증 구조 매핑 (주장-근거-결론)
- [ ] 수사적 장치 탐지 (은유, 반복, 대조 등)

### 6.2 난이도 분석

- [ ] 어휘 복잡도 측정
- [ ] 문장 구조 복잡도 평가
- [ ] 배경지식 요구 수준 판단
- [ ] 논리적 깊이 측정

### 6.3 질문 포인트 자동 생성

- [ ] 논리적 비약 지점 표시
- [ ] 모호한 지시어 탐지
- [ ] 생략된 전제 추정
- [ ] 반증 가능 지점 마킹

---

## 7. 사용자 인터페이스 요구사항

### 7.1 대화 흐름 설계

- [ ] 질문 → 사용자 답변 → 근거 요구 → 심화 질문 루프
- [ ] 사용자가 막힐 경우 힌트 요청 버튼 제공
- [ ] 이전 질문으로 돌아가기 기능
- [ ] 텍스트 하이라이트 기능 (근거 제시 시)

### 7.2 진행 상황 표시

- [ ] 현재 독해 단계 표시 (이해 → 분석 → 평가 → 창조)
- [ ] 사용한 질문 유형 표시 (QAR, 블룸, 소크라테스 등)
- [ ] 텍스트 앵커링 성공률 표시
- [ ] 논리적 추론 정확도 피드백

### 7.3 학습 이력 관리

- [ ] 읽은 텍스트별 이해도 기록
- [ ] 약점 패턴 분석 (예: 논리적 허점 찾기 약함)
- [ ] 성장 곡선 시각화
- [ ] 추천 학습 전략 제시

---

## 8. 기술 스택 및 구현 요구사항

### 8.1 텍스트 분석 엔진

- [ ] NLP 라이브러리 통합 (spaCy, NLTK 등)
- [ ] 논증 구조 파싱 알고리즘
- [ ] 논리적 오류 패턴 매칭 시스템
- [ ] 키워드 추출 및 개념 네트워크 생성

### 8.2 데이터 저장

- [ ] 사용자별 학습 이력 DB
- [ ] 텍스트별 분석 결과 캐싱
- [ ] 질문-답변 쌍 저장 및 재활용
- [ ] 평가 메트릭 누적 데이터

---

## 9. 성능 지표 (KPI)

### 9.1 교육적 효과 측정

- [ ] 텍스트 앵커링 성공률 (사용자가 본문 근거를 제시한 비율)
- [ ] 논리적 추론 정확도 향상률
- [ ] 자발적 질문 생성 횟수 증가
- [ ] 세션당 평균 사고 깊이 (블룸 분류학 단계)

### 9.2 시스템 성능 측정

- [ ] 질문 생성 적절성 (사용자 피드백 기반)
- [ ] 힌트 제공 타이밍 적정성
- [ ] 대화 이탈률 (사용자가 중도 포기한 비율)
- [ ] 평균 세션 지속 시간

### 9.3 콘텐츠 품질 지표

- [ ] 질문 유형 다양성 (QAR, 소크라테스, 블룸 등 골고루 사용)
- [ ] 중복 질문 방지율
- [ ] 텍스트 난이도와 질문 난이도 적합성

---

## 10. 우선순위 및 로드맵

### Phase 1: MVP (최소 기능 제품)
- [ ] QAR 기반 질문 생성 (4가지 유형)
- [ ] 소크라테스식 역질문 시스템
- [ ] 텍스트 앵커링 강제 메커니즘
- [ ] 기본 힌트 시스템

### Phase 2: 논리 분석 강화
- [ ] 툴민 모델 기반 논증 구조 분석
- [ ] 블룸의 분류학 적용
- [ ] 논리적 오류 탐지 시스템
- [ ] 폴-엘더 8요소 평가

### Phase 3: 고급 전략 통합
- [ ] 여섯 색깔 모자 기법
- [ ] QtA 및 DR-TA 통합
- [ ] 개념도 자동 생성
- [ ] 수사학적 분석 (로고스, 에토스, 파토스)

### Phase 4: 개인화 및 최적화
- [ ] 근접발달영역 기반 난이도 자동 조절
- [ ] 학습 이력 기반 추천 시스템
- [ ] 다중 텍스트 통합 분석 (Syntopical Reading)
- [ ] 실시간 성장 피드백 대시보드

---

## 11. 제약 조건 및 고려사항

### 11.1 교육학적 제약
- [ ] 사용자가 스스로 답을 발견하는 과정 보장
- [ ] 과도한 힌트로 인한 학습 효과 저하 방지
- [ ] 사용자 좌절감과 도전 과제의 균형 유지

### 11.2 기술적 제약
- [ ] LLM 응답 지연 시간 관리 (3초 이내)
- [ ] 컨텍스트 윈도우 제한 (긴 텍스트 처리)
- [ ] 질문 생성 품질의 일관성 유지

### 11.3 윤리적 고려사항
- [ ] 정치적/윤리적 중립성 유지
- [ ] 민감한 주제(성, 종교, 정치)에서의 가치관 강요 금지
- [ ] 사용자 프라이버시 보호 (학습 데이터)

---

## 12. 검증 및 테스트

### 12.1 기능 테스트
- [ ] 각 질문 유형별 생성 정확도 검증
- [ ] 힌트 시스템 단계별 적절성 평가
- [ ] 논리적 오류 탐지 정밀도 측정

### 12.2 사용자 테스트
- [ ] 다양한 연령대/수준별 베타 테스트
- [ ] A/B 테스트 (질문 스타일, 힌트 타이밍)
- [ ] 사용자 만족도 및 학습 효과 설문

### 12.3 엣지 케이스 처리
- [ ] 매우 짧은 텍스트 (<10자)
- [ ] 매우 긴 텍스트 (>10,000자)
- [ ] 시, 소설 등 창작물
- [ ] 통계/수식이 많은 학술 논문

---

## 부록: 질문 템플릿 예시

### A. QAR 템플릿
```
- 바로 거기: "본문에서 [키워드]는 무엇이라고 명시되어 있나요?"
- 생각하고 찾기: "1문단과 3문단을 종합하면, [주제]에 대한 저자의 관점은?"
- 저자와 내 생각: "저자가 말한 [개념]을 당신의 경험에 비추어 보면?"
- 내 힘으로: "이 글의 주제와 관련하여, 당신이라면 어떤 해결책을 제시하겠나요?"
```

### B. 소크라테스 템플릿
```
- 전제 확인: "그 해석은 [X]가 반드시 참이라는 가정이 필요한데, 그 근거는?"
- 증거 탐구: "본문의 정확히 어느 문장이 그 결론을 뒷받침하나요?"
- 관점 전환: "만약 [반대 입장]이라면 이 문장을 어떻게 해석할까요?"
- 함축 질문: "그 논리대로라면, 다음 단락에서는 반드시 [Y]가 언급되어야 하는데?"
```

### C. 툴민 모델 템플릿
```
- 영장 탐색: "[데이터]에서 [주장]으로 가는 논리적 다리는 무엇인가요?"
- 보강 요구: "그 연결 고리를 뒷받침하는 추가 근거가 본문에 있나요?"
- 반박 고려: "어떤 상황에서 이 주장이 성립하지 않을 수 있나요?"
```
