"""
Gemini ê¸°ë°˜ ì§ˆì  í‰ê°€ ëª¨ë“ˆ
- ì¶”ë¡  ê¹Šì´
- ë¹„íŒì  ì‚¬ê³ 
- ë¬¸í•™ì  ì´í•´
"""

import os
import json
from pathlib import Path
from typing import Dict, Optional
from datetime import datetime


class GeminiEvaluator:
    """Gemini Pro ê¸°ë°˜ ì§ˆì  í‰ê°€"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        rubric_path: str = "configs/rubric.json"
    ):
        """
        Args:
            api_key: Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEY ì‚¬ìš©)
            rubric_path: í‰ê°€ ë£¨ë¸Œë¦­ íŒŒì¼ ê²½ë¡œ
        """
        self.api_key = api_key or os.getenv("GEMINI_API_KEY", "")
        self.model = None
        self.rubric = self._load_rubric(rubric_path)

        self._init_model()

    def _load_rubric(self, rubric_path: str) -> Dict:
        """í‰ê°€ ë£¨ë¸Œë¦­ ë¡œë“œ"""
        try:
            with open(rubric_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âš ï¸ ë£¨ë¸Œë¦­ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {rubric_path}")
            return self._default_rubric()

    def _default_rubric(self) -> Dict:
        """ê¸°ë³¸ ë£¨ë¸Œë¦­"""
        return {
            "ì¶”ë¡ _ê¹Šì´": {
                "5": "ë‹¤ì¸µì  ì‚¬ê³ , í…ìŠ¤íŠ¸ ë§¥ë½ ê¹Šì´ ì´í•´",
                "4": "ë…¼ë¦¬ì  ì¶”ë¡ , ë§¥ë½ ì—°ê²°",
                "3": "ê¸°ë³¸ì  ì¶”ë¡ ",
                "2": "ë‹¨í¸ì  ì´í•´",
                "1": "í‘œë©´ì  ë°˜ì‘"
            },
            "ë¹„íŒì _ì‚¬ê³ ": {
                "5": "ë…ìì  í•´ì„, ë‹¤ì–‘í•œ ê´€ì ",
                "4": "ëŒ€ì•ˆì  í•´ì„ ì‹œë„",
                "3": "ì§ì ‘ì  ë‹µë³€",
                "2": "ë‹¨ìˆœ ì •ë³´ íšŒìƒ",
                "1": "ê´€ë ¨ ì—†ëŠ” ì‘ë‹µ"
            },
            "ë¬¸í•™ì _ì´í•´": {
                "5": "ì‹œëŒ€/ë¬¸í™” ë§¥ë½ í†µí•©",
                "4": "ì‘í’ˆ êµ¬ì¡° ì´í•´",
                "3": "ì¤„ê±°ë¦¬ ì´í•´",
                "2": "ë¶€ë¶„ì  ì´í•´",
                "1": "ì˜¤í•´"
            }
        }

    def _init_model(self):
        """Gemini ëª¨ë¸ ì´ˆê¸°í™”"""
        if not self.api_key:
            print("âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_keyë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”.")
            return

        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-pro')
            print("âœ… Gemini Pro ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError:
            print("âš ï¸ google-generativeai íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            self.model = None
        except Exception as e:
            print(f"âš ï¸ Gemini ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.model = None

    def evaluate(
        self,
        student_input: str,
        thought_log: str,
        context: Optional[str] = None
    ) -> Dict:
        """
        ì§ˆì  í‰ê°€ ìˆ˜í–‰

        Args:
            student_input: í•™ìƒ ì§ˆë¬¸/ë‹µë³€
            thought_log: AIê°€ ìƒì„±í•œ ì‚¬ê³ ë¡œê·¸
            context: ì¶”ê°€ ë§¥ë½ (ì‘í’ˆëª… ë“±)

        Returns:
            Dict: í‰ê°€ ê²°ê³¼
        """
        if not self.model:
            return self._fallback_eval()

        # ë£¨ë¸Œë¦­ í…ìŠ¤íŠ¸ ìƒì„±
        rubric_text = self._format_rubric()

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ê³ ì „ë¬¸í•™ êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ë¡œì„œ í•™ìƒì˜ ì‚¬ê³ ë¥¼ í‰ê°€í•˜ì„¸ìš”.

[í‰ê°€ ë£¨ë¸Œë¦­]
{rubric_text}

[ë§¥ë½]
{context or "ê³ ì „ë¬¸í•™ í•™ìŠµ"}

[í•™ìƒ ì§ˆë¬¸/ë‹µë³€]
{student_input}

[ì‚¬ê³ ë¡œê·¸]
{thought_log}

[í‰ê°€ ì§€ì¹¨]
1. ê° ì°¨ì›ë³„ë¡œ 1-5ì  ì²™ë„ë¡œ í‰ê°€í•˜ì„¸ìš”.
2. ê° ì ìˆ˜ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.
3. í•™ìƒì˜ ì‚¬ê³  ê³¼ì •ì„ ê¸ì •ì ìœ¼ë¡œ í‰ê°€í•˜ë©´ì„œ ê°œì„ ì ë„ ì œì‹œí•˜ì„¸ìš”.

[ì¶œë ¥ í˜•ì‹ - JSONë§Œ ì¶œë ¥]
{{
  "ì¶”ë¡ _ê¹Šì´": {{"ì ìˆ˜": X, "í”¼ë“œë°±": "..."}},
  "ë¹„íŒì _ì‚¬ê³ ": {{"ì ìˆ˜": X, "í”¼ë“œë°±": "..."}},
  "ë¬¸í•™ì _ì´í•´": {{"ì ìˆ˜": X, "í”¼ë“œë°±": "..."}},
  "ì¢…í•©_í‰ê°€": "...",
  "ê°•ì ": ["...", "..."],
  "ê°œì„ ì ": ["...", "..."]
}}"""

        try:
            response = self.model.generate_content(prompt)
            evaluation = self._parse_response(response.text)

            # ì´ì  ë° í‰ê·  ê³„ì‚°
            scores = [
                evaluation.get("ì¶”ë¡ _ê¹Šì´", {}).get("ì ìˆ˜", 3),
                evaluation.get("ë¹„íŒì _ì‚¬ê³ ", {}).get("ì ìˆ˜", 3),
                evaluation.get("ë¬¸í•™ì _ì´í•´", {}).get("ì ìˆ˜", 3)
            ]
            evaluation["ì´ì "] = sum(scores)
            evaluation["í‰ê· "] = round(sum(scores) / 3, 2)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            evaluation["metadata"] = {
                "timestamp": datetime.now().isoformat(),
                "model": "gemini-pro"
            }

            return evaluation

        except Exception as e:
            print(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._fallback_eval()

    def _format_rubric(self) -> str:
        """ë£¨ë¸Œë¦­ì„ ë¬¸ìì—´ë¡œ í¬ë§·"""
        rubric = self.rubric.get("qualitative_rubric", self._default_rubric())

        text = ""
        for dimension, criteria in rubric.items():
            text += f"\n{dimension}:\n"
            if isinstance(criteria, dict) and "criteria" in criteria:
                criteria = criteria["criteria"]
            for score, desc in criteria.items():
                text += f"  {score}ì : {desc}\n"

        return text

    def _parse_response(self, response_text: str) -> Dict:
        """ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_text = response_text
            if "```json" in json_text:
                json_text = json_text.split("```json")[1].split("```")[0]
            elif "```" in json_text:
                json_text = json_text.split("```")[1].split("```")[0]

            return json.loads(json_text.strip())

        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ ì¶”ì¶œ ì‹œë„
            return self._extract_from_text(response_text)

    def _extract_from_text(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ í‰ê°€ ì •ë³´ ì¶”ì¶œ (fallback)"""
        import re

        result = {
            "ì¶”ë¡ _ê¹Šì´": {"ì ìˆ˜": 3, "í”¼ë“œë°±": ""},
            "ë¹„íŒì _ì‚¬ê³ ": {"ì ìˆ˜": 3, "í”¼ë“œë°±": ""},
            "ë¬¸í•™ì _ì´í•´": {"ì ìˆ˜": 3, "í”¼ë“œë°±": ""},
            "ì¢…í•©_í‰ê°€": text[:200] if text else "í‰ê°€ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨"
        }

        # ì ìˆ˜ íŒ¨í„´ ì°¾ê¸°
        patterns = {
            "ì¶”ë¡ ": r"ì¶”ë¡ .*?(\d)",
            "ë¹„íŒ": r"ë¹„íŒ.*?(\d)",
            "ë¬¸í•™": r"ë¬¸í•™.*?(\d)"
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, text)
            if match:
                score = int(match.group(1))
                if key == "ì¶”ë¡ ":
                    result["ì¶”ë¡ _ê¹Šì´"]["ì ìˆ˜"] = score
                elif key == "ë¹„íŒ":
                    result["ë¹„íŒì _ì‚¬ê³ "]["ì ìˆ˜"] = score
                elif key == "ë¬¸í•™":
                    result["ë¬¸í•™ì _ì´í•´"]["ì ìˆ˜"] = score

        return result

    def _fallback_eval(self) -> Dict:
        """í´ë°± í‰ê°€ (API ì‚¬ìš© ë¶ˆê°€ ì‹œ)"""
        return {
            "ì¶”ë¡ _ê¹Šì´": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "API ì—°ê²° í•„ìš”"},
            "ë¹„íŒì _ì‚¬ê³ ": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "API ì—°ê²° í•„ìš”"},
            "ë¬¸í•™ì _ì´í•´": {"ì ìˆ˜": 3, "í”¼ë“œë°±": "API ì—°ê²° í•„ìš”"},
            "ì¢…í•©_í‰ê°€": "Gemini API ì—°ê²° í›„ í‰ê°€ ê°€ëŠ¥",
            "ì´ì ": 9,
            "í‰ê· ": 3.0,
            "ê°•ì ": [],
            "ê°œì„ ì ": ["Gemini API í‚¤ ì„¤ì • í•„ìš”"],
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "model": "fallback"
            }
        }

    def batch_evaluate(
        self,
        evaluations: list,
        output_path: Optional[str] = None
    ) -> list:
        """
        ë°°ì¹˜ í‰ê°€

        Args:
            evaluations: [{"student_input": ..., "thought_log": ..., "context": ...}, ...]
            output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ

        Returns:
            list: í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        from tqdm import tqdm

        results = []
        for item in tqdm(evaluations, desc="í‰ê°€ ì¤‘"):
            result = self.evaluate(
                student_input=item.get("student_input", ""),
                thought_log=item.get("thought_log", ""),
                context=item.get("context")
            )
            result["input_data"] = item
            results.append(result)

        # ì €ì¥
        if output_path:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                for item in results:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')

            print(f"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {output_path}")

        return results

    def generate_report(
        self,
        evaluation: Dict,
        include_rubric: bool = True
    ) -> str:
        """
        í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            evaluation: í‰ê°€ ê²°ê³¼
            include_rubric: ë£¨ë¸Œë¦­ í¬í•¨ ì—¬ë¶€

        Returns:
            str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë¦¬í¬íŠ¸
        """
        report = "# ğŸ“Š í•™ìƒ ì‚¬ê³ ë ¥ í‰ê°€ ë¦¬í¬íŠ¸\n\n"

        # ì¢…í•© ì ìˆ˜
        report += "## ì¢…í•© ê²°ê³¼\n"
        report += f"- **ì´ì **: {evaluation.get('ì´ì ', 'N/A')} / 15\n"
        report += f"- **í‰ê· **: {evaluation.get('í‰ê· ', 'N/A')} / 5.0\n\n"

        # ì°¨ì›ë³„ í‰ê°€
        report += "## ì„¸ë¶€ í‰ê°€\n\n"

        dimensions = ["ì¶”ë¡ _ê¹Šì´", "ë¹„íŒì _ì‚¬ê³ ", "ë¬¸í•™ì _ì´í•´"]
        for dim in dimensions:
            dim_eval = evaluation.get(dim, {})
            score = dim_eval.get("ì ìˆ˜", "N/A")
            feedback = dim_eval.get("í”¼ë“œë°±", "")

            report += f"### {dim.replace('_', ' ')}\n"
            report += f"- **ì ìˆ˜**: {score} / 5\n"
            report += f"- **í”¼ë“œë°±**: {feedback}\n\n"

        # ì¢…í•© í‰ê°€
        report += "## ì¢…í•© í‰ê°€\n"
        report += f"{evaluation.get('ì¢…í•©_í‰ê°€', '')}\n\n"

        # ê°•ì  ë° ê°œì„ ì 
        strengths = evaluation.get("ê°•ì ", [])
        improvements = evaluation.get("ê°œì„ ì ", [])

        if strengths:
            report += "## âœ… ê°•ì \n"
            for s in strengths:
                report += f"- {s}\n"
            report += "\n"

        if improvements:
            report += "## ğŸ’¡ ê°œì„ ì \n"
            for i in improvements:
                report += f"- {i}\n"
            report += "\n"

        return report


# ì§ì ‘ ì‹¤í–‰ ì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    evaluator = GeminiEvaluator()

    test_result = evaluator.evaluate(
        student_input="ì¶˜í–¥ì „ì—ì„œ ì´ëª½ë£¡ì´ ì‹ ë¶„ì„ ìˆ¨ê¸´ ì´ìœ ê°€ ë­”ê°€ìš”?",
        thought_log="í•™ìƒì´ ì‹ ë¶„ì œì™€ ì‚¬ë‘ì˜ ì§„ì •ì„±ì„ ì—°ê²°ì§€ì–´ ì‚¬ê³  ì‹œì‘. ì¶”ë¡  ê¹Šì´: ì¤‘ìƒ.",
        context="ì¶˜í–¥ì „"
    )

    print("=" * 60)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("=" * 60)
    print(json.dumps(test_result, ensure_ascii=False, indent=2))
