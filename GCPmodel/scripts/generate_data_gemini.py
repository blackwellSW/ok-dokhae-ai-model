#!/usr/bin/env python3
"""
Gemini 2.5 Proë¡œ ê³ ì „ë¬¸í•™ Socratic dialogue ë°ì´í„° ìƒì„±
GCP í¬ë ˆë”§ ìë™ ì‚¬ìš©
"""

import os
import json
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from google.cloud import aiplatform
import vertexai
from vertexai.generative_models import GenerativeModel

# ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ì„¤ì •
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/Users/choidamul/GCPmodel/.gcp-key.json"

# GCP ì„¤ì •
PROJECT_ID = "knu-team-03"
LOCATION = "us-central1"

# Gemini ëª¨ë¸ ì´ˆê¸°í™” (2.0 Flash - ì•ˆì •ì ì¸ JSON ì¶œë ¥)
vertexai.init(project=PROJECT_ID, location=LOCATION)
model = GenerativeModel("gemini-2.0-flash-001")

# ê³ ì „ë¬¸í•™ ì‘í’ˆ ëª©ë¡ (100ê°œ)
CLASSICAL_WORKS = [
    # ê³ ì „ì†Œì„¤ (30ê°œ)
    "ì¶˜í–¥ì „", "í™ê¸¸ë™ì „", "êµ¬ìš´ëª½", "ì‹¬ì²­ì „", "í¥ë¶€ì „", "ë°•ì”¨ì „", "ì¥í™”í™ë ¨ì „", "ìš´ì˜ì „", "ìµœì²™ì „", "ì‚¬ì”¨ë‚¨ì •ê¸°",
    "ì°½ì„ ê°ì˜ë¡", "ìˆ™í–¥ì „", "ì¡°ì›…ì „", "ìœ ì¶©ë ¬ì „", "ì†ŒëŒ€ì„±ì „", "ì„ì§„ë¡", "ì™„ì›”íšŒë§¹ì—°", "ëª…ì£¼ë³´ì›”ë¹™", "ì˜¥ë£¨ëª½", "ì˜¥ë‹¨ì¶˜ì „",
    "ë°°ë¹„ì¥ì „", "ì–‘ë°˜ì „", "í—ˆìƒì „", "í˜¸ì§ˆ", "ë¯¼ì˜¹ì „", "ìš°ìƒì „", "ì˜ˆë•ì„ ìƒì „", "ë‚¨ì—¼ë¶€ì£¼ì§€", "ì „ìš°ì¹˜ì „", "ì¥ë¼ì „",

    # ê³ ì „ì‹œê°€ (20ê°œ)
    "ìš©ë¹„ì–´ì²œê°€", "ì•…ì¥ê°€ì‚¬", "ì •ìì‚¬", "ì²˜ìš©ê°€", "ì„œë™ìš”", "ì œë§ë§¤ê°€", "ì°¬ê¸°íŒŒë‘ê°€", "í˜œì„±ê°€", "ì›ì™•ìƒê°€", "ëª¨ì£½ì§€ë‘ê°€",
    "ì²­ì‚°ë³„ê³¡", "ì„œê²½ë³„ê³¡", "ê°€ì‹œë¦¬", "ë™ë™", "ì´ìƒê³¡", "ì •ê³¼ì •", "ë§Œì „ì¶˜ë³„ì‚¬", "ìŒí™”ì ", "ì •ì„ê°€", "ì‚¬ëª¨ê³¡",

    # ì‹œì¡° (20ê°œ)
    "ì˜¤ìš°ê°€", "í›ˆë¯¼ê°€", "ë‹¨ì‹¬ê°€", "í•œê±°ì‹­íŒ”ê³¡", "ë„ì‚°ì‹­ì´ê³¡", "ì–´ë¶€ì‚¬ì‹œì‚¬", "ì†ë¯¸ì¸ê³¡", "ì‚¬ë¯¸ì¸ê³¡", "ë©´ì–‘ì •ê°€", "ì„±ì‚°ë³„ê³¡",
    "ê´€ë™ë³„ê³¡", "ì‚¬ì œê³¡", "ëˆ„í•­ì‚¬", "ì¼ë™ì¥ìœ ê°€", "ê²¬íšŒìš”", "ë†ê°€ì›”ë ¹ê°€", "ê·œì›ê°€", "ë§¤í™”ì‚¬", "ë¶ì°¬ê°€", "ë…ë¦½êµ°ê°€",

    # ê°€ì‚¬ë¬¸í•™ (4ê°œ + ê¸°íƒ€)
    "ìƒì¶˜ê³¡", "ë‚™ë¯¼ê°€", "ì¶œìƒˆê³¡", "ê´€ë™ë³„ê³¡", # ê´€ë™ë³„ê³¡ ì¤‘ë³µì´ë‚˜ ë¦¬ìŠ¤íŠ¸ ìœ ì§€

    # í•œë¬¸í•™ (10ê°œ)
    "ê¸ˆì˜¤ì‹ í™”", "ê¸°ì¬ê¸°ì´", "ì–´ìš°ì•¼ë‹´", "ì²­êµ¬ì•¼ë‹´", "ë™íŒ¨ë½ì†¡", "íƒë¦¬ì§€", "ì„ì›ê²½ì œì§€", "ì„±í˜¸ì‚¬ì„¤", "ëª©ë¯¼ì‹¬ì„œ", "í í ì‹ ì„œ",

    # íŒì†Œë¦¬ (10ê°œ)
    "ì¶˜í–¥ê°€", "ì‹¬ì²­ê°€", "í¥ë³´ê°€", "ìˆ˜ê¶ê°€", "ì ë²½ê°€", "ë³€ê°•ì‡ ê°€", "ë°°ë¹„ì¥íƒ€ë ¹", "ê°•ë¦‰ë§¤í™”íƒ€ë ¹", "ë¬´ìˆ™ì´íƒ€ë ¹", "ì¥ë¼íƒ€ë ¹",

    # í˜„ëŒ€ ì „í™˜ê¸° (10ê°œ)
    "í˜ˆì˜ë£¨", "ììœ ì¢…", "ì€ì„¸ê³„", "ì¹˜ì•…ì‚°", "ë¬´ì •", "ë§Œì„¸ì „", "ë¹ˆì²˜", "ê³ ëª©í™”", "Bì‚¬ê°ê³¼ ëŸ¬ë¸Œë ˆí„°", "ë‚ ê°œ"
]

# ì¤‘ë³µ ì œê±° ë° ë³´ì • (100ê°œ ê·¼ì‚¬ì¹˜ ë§ì¶¤)
CLASSICAL_WORKS = list(set(CLASSICAL_WORKS))

# ì§ˆë¬¸ ìœ í˜• (10ê°€ì§€)
QUESTION_TYPES = [
    "ë“±ì¥ì¸ë¬¼ì˜ ì‹¬ë¦¬ ë¶„ì„",
    "ê°ˆë“± êµ¬ì¡° íŒŒì•…",
    "ì‹œëŒ€ì  ë°°ê²½ê³¼ ì‚¬íšŒìƒ",
    "ì£¼ì œ ì˜ì‹ íƒêµ¬",
    "í‘œí˜„ ê¸°ë²•ê³¼ ë¬¸ì²´",
    "í˜„ëŒ€ì  ì˜ë¯¸ì™€ ê°€ì¹˜",
    "ì‘í’ˆ êµ¬ì¡°ì™€ ì „ê°œ",
    "ìƒì§•ê³¼ ë¹„ìœ  í•´ì„",
    "ì¸ë¬¼ ê°„ ê´€ê³„ ë¶„ì„",
    "ì‘í’ˆì˜ êµí›ˆê³¼ ë©”ì‹œì§€"
]

# Socratic dialogue ìƒì„± í”„ë¡¬í”„íŠ¸
PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ ê³ ì „ë¬¸í•™ êµìœ¡ ì „ë¬¸ê°€ì´ì 'Socratic Method'ì˜ ëŒ€ê°€ì…ë‹ˆë‹¤.
í•™ìƒë“¤ì´ ì‘í’ˆì˜ ê¹Šì€ ì˜ë¯¸ë¥¼ ìŠ¤ìŠ¤ë¡œ ê¹¨ë‹«ë„ë¡ ìœ ë„í•˜ëŠ” **Socratic dialogue ë°ì´í„°**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‘í’ˆ**: {work}
**ì§ˆë¬¸ ìœ í˜•**: {question_type}

### âœï¸ ì‘ì„± ê°€ì´ë“œ
1. **ì •ë‹µì„ ë°”ë¡œ ì•Œë ¤ì£¼ì§€ ë§ˆì„¸ìš”.** (ì„¤ëª…ì¡° ê¸ˆì§€)
2. **ê¼¬ë¦¬ì— ê¼¬ë¦¬ë¥¼ ë¬´ëŠ” ì§ˆë¬¸**ìœ¼ë¡œ í•™ìƒì˜ ì‚¬ê³ ë¥¼ í™•ì¥ì‹œí‚¤ì„¸ìš”.
3. **í•µì‹¬ ì§ˆë¬¸ â†’ êµ¬ì²´ì  ìƒí™©ì˜ í™•ì¸ â†’ ëª¨ìˆœì˜ ì§€ì  â†’ ì¼ë°˜í™”/ì‹¬í™”** ë‹¨ê³„ë¡œ ìœ ë„í•˜ì„¸ìš”.
4. **ë°˜ì–´ë²•, ê°€ì •ë²•("ë§Œì•½ ~ë¼ë©´?")**ì„ ì ê·¹ í™œìš©í•˜ì—¬ í•™ìƒì´ ë‹¹ì—°í•˜ê²Œ ì—¬ê¸°ë˜ ì‚¬ì‹¤ì„ ë’¤ì§‘ì–´ ë³´ê²Œ í•˜ì„¸ìš”.

### âŒ ë‚˜ìœ ì˜ˆ (ì§ì ‘ ë‹µë³€)
ì´ëª½ë£¡ì´ ë³€ì‚¬ë˜ê°€ ëœ ê²ƒì€ ì‹ ë¶„ì œë„ì˜ ëª¨ìˆœì„ í•´ê²°í•˜ê¸° ìœ„í•œ ì¥ì¹˜ì…ë‹ˆë‹¤.

### âœ… ì¢‹ì€ ì˜ˆ (Socratic ì§ˆë¬¸)
"ë¨¼ì € ìƒê°í•´ë´…ì‹œë‹¤. ì´ëª½ë£¡ì€ ì–´ë–¤ ì‹ ë¶„ì´ì—ˆë‚˜ìš”? ê·¸ë¦¬ê³  ì¶˜í–¥ì€ìš”? 
ë‘ ì‚¬ëŒì˜ ì‹ ë¶„ ì°¨ì´ê°€ ê·¸ ë‹¹ì‹œ ì‚¬íšŒì—ì„œ ì™œ ë¬¸ì œê°€ ë˜ì—ˆì„ê¹Œìš”?

ë‹¹ì‹œ ì¡°ì„ ì‹œëŒ€ì—ëŠ” ì–‘ë°˜ê³¼ ê¸°ìƒì´ ììœ ë¡­ê²Œ ê²°í˜¼í•  ìˆ˜ ìˆì—ˆì„ê¹Œìš”? 
ê·¸ë ‡ë‹¤ë©´ ì‘ê°€ëŠ” ì™œ í•˜í•„ ì´ëª½ë£¡ì„ ë³€ì‚¬ë˜, ì¦‰ ê¶Œë ¥ì„ ê°€ì§„ ê´€ë¦¬ë¡œ ë‹¤ì‹œ ë“±ì¥ì‹œì¼°ì„ê¹Œìš”?

ì´ê²ƒì„ í†µí•´ ì‘ê°€ê°€ ë§í•˜ê³  ì‹¶ì—ˆë˜ ê²ƒì€ ë‹¨ìˆœí•œ ì‚¬ë‘ ì´ì•¼ê¸°ì¼ê¹Œìš”, ì•„ë‹ˆë©´ ë‹¤ë¥¸ ë¬´ì–¸ê°€ê°€ ìˆì„ê¹Œìš”? 
ê°œì¸ì˜ ì‚¬ë‘ê³¼ ê²¬ê³ í•œ ì‹ ë¶„ì œë„ê°€ ì¶©ëŒí•  ë•Œ, ì´ ì†Œì„¤ì€ ì–´ë–¤ í•´ê²°ì±…ì„ ì œì‹œí•˜ê³  ìˆë‚˜ìš”?"

---

### ğŸ“ ìƒì„± í¬ë§· (JSON)

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

{{
  "instruction": "ë‹¤ìŒ ì§€ë¬¸ì„ ì½ê³  ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. í•™ìƒì˜ ì‚¬ê³ ë¥¼ ìœ ë„í•˜ë©° ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.",
  "input": "[ì§€ë¬¸]\\n{{ì§€ë¬¸ ë‚´ìš© (200-300ì)}}\\n\\n[ì§ˆë¬¸]\\n{{ì‚¬ê³  ìœ ë„ìš© í•µì‹¬ ì§ˆë¬¸ (30-50ì)}}",
  "output": "{{Socratic ë‹µë³€ (500-800ì): ì§ˆë¬¸ íë¦„ìœ¼ë¡œ êµ¬ì„±ëœ ë‹µë³€}}",
  "metadata": {{
    "work": "{work}",
    "question_type": "{question_type}",
    "dataset": "classical_socratic"
  }}
}}
"""

def generate_sample(work: str, question_type: str, retry: int = 3) -> dict:
    """Geminië¡œ 1ê°œ ìƒ˜í”Œ ìƒì„±"""
    prompt = PROMPT_TEMPLATE.format(work=work, question_type=question_type)

    for attempt in range(retry):
        try:
            # Rate Limiting (Quota ì´ˆê³¼ ë°©ì§€)
            time.sleep(0.3) 

            response = model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.9,
                    "top_p": 0.95,
                    "top_k": 40,
                    "max_output_tokens": 2048,
                    "response_mime_type": "application/json",
                }
            )

            # JSON íŒŒì‹±
            text = response.text.strip()
            
            # JSON í´ë¦¬ë‹
            if text.startswith("```json"):
                text = text[7:]
            if text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]

            data = json.loads(text.strip())
            
            # ë©”íƒ€ë°ì´í„° ê°•ì œ ì£¼ì… (ëª¨ë¸ì´ ì‹¤ìˆ˜í•  ê²½ìš° ëŒ€ë¹„)
            if "metadata" not in data:
                data["metadata"] = {}
            data["metadata"]["work"] = work
            data["metadata"]["question_type"] = question_type
            data["metadata"]["dataset"] = "classical_socratic"
            
            return data

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ [{work}] (ì‹œë„ {attempt + 1}/{retry}): {e}")
            if attempt < retry - 1:
                time.sleep(2)
            else:
                return None

    return None

def generate_all_samples(total: int = 3000, workers: int = 5):
    """ë³‘ë ¬ë¡œ ëª¨ë“  ìƒ˜í”Œ ìƒì„±"""
    
    print("=" * 60)
    print("ğŸš€ Gemini 1.5 Pro - Socratic Data Generation")
    print("=" * 60)
    print(f"ëª©í‘œ: {total}ê°œ ìƒ˜í”Œ")
    print(f"ì‘í’ˆ ìˆ˜: {len(CLASSICAL_WORKS)}ê°œ")
    print(f"ì§ˆë¬¸ ìœ í˜•: {len(QUESTION_TYPES)}ê°œ")
    print("=" * 60)

    # ì‘í’ˆ Ã— ì§ˆë¬¸ ìœ í˜• ì¡°í•© ìƒì„±
    tasks = []
    
    # 1. ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì‘í’ˆê³¼ ìœ í˜•ì„ í•œ ë²ˆì”©ì€ í›‘ê¸° (100 * 10 = 1000ê°œ)
    # 2. ë‚˜ë¨¸ì§€ëŠ” ëœë¤í•˜ê²Œ ë¶„í¬
    import random
    
    # ê¸°ë³¸ ì¡°í•©
    base_combinations = []
    for work in CLASSICAL_WORKS:
        for q_type in QUESTION_TYPES:
            base_combinations.append((work, q_type))
            
    random.shuffle(base_combinations)
    
    # ëª©í‘œ ìˆ˜ëŸ‰ì— ë§ê²Œ íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ ì‘ì„±
    if total <= len(base_combinations):
        tasks = base_combinations[:total]
    else:
        # ì¼ë‹¨ ë‹¤ ë„£ê³ 
        tasks.extend(base_combinations)
        # ë‚¨ì€ ë§Œí¼ ëœë¤ ë½‘ê¸°
        remaining = total - len(tasks)
        for _ in range(remaining):
            tasks.append((random.choice(CLASSICAL_WORKS), random.choice(QUESTION_TYPES)))
    
    # ì…”í”Œ
    random.shuffle(tasks)

    # ë³‘ë ¬ ìƒì„±
    results = []
    failed = 0

    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {
            executor.submit(generate_sample, work, qt): (work, qt)
            for work, qt in tasks
        }

        for i, future in enumerate(as_completed(futures), 1):
            try:
                result = future.result()
                if result:
                    results.append(result)
                    print(f"âœ… [{i}/{total}] {result['metadata']['work']} - {result['metadata']['question_type']}")
                else:
                    failed += 1
                    print(f"âŒ [{i}/{total}] ìƒì„± ì‹¤íŒ¨")

                if i % 50 == 0:
                    print(f"\nğŸ“Š ì§„í–‰ë¥ : {i}/{total} (ì„±ê³µ: {len(results)}, ì‹¤íŒ¨: {failed})\n")

            except Exception as e:
                failed += 1
                print(f"âŒ [{i}/{total}] ì˜ˆì™¸: {e}")

    return results

def save_datasets(samples: list, output_dir: str = "data/augmented"):
    """Train/Valid ë¶„í•  ë° ì €ì¥"""

    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # 80/20 ë¶„í•  (2400 / 600)
    import random
    random.shuffle(samples)
    
    split_ratio = 0.8
    split_idx = int(len(samples) * split_ratio)

    train_samples = samples[:split_idx]
    valid_samples = samples[split_idx:]

    train_path = f"{output_dir}/train_socratic.jsonl"
    valid_path = f"{output_dir}/valid_socratic.jsonl"

    with open(train_path, 'w', encoding='utf-8') as f:
        for sample in train_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')

    with open(valid_path, 'w', encoding='utf-8') as f:
        for sample in valid_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')

    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ!")
    print(f"   Train: {train_path} ({len(train_samples)}ê°œ)")
    print(f"   Valid: {valid_path} ({len(valid_samples)}ê°œ)")

    return train_path, valid_path

def upload_to_gcs(train_path: str, valid_path: str):
    """GCS ì—…ë¡œë“œ"""
    try:
        from google.cloud import storage
        client = storage.Client(project=PROJECT_ID)
        bucket = client.bucket("knu-team-03-data")

        blob_train = bucket.blob("classical-literature/gemma/train_socratic.jsonl")
        blob_train.upload_from_filename(train_path)
        print(f"â˜ï¸ GCS Upload: gs://knu-team-03-data/{blob_train.name}")

        blob_valid = bucket.blob("classical-literature/gemma/valid_socratic.jsonl")
        blob_valid.upload_from_filename(valid_path)
        print(f"â˜ï¸ GCS Upload: gs://knu-team-03-data/{blob_valid.name}")
        
    except Exception as e:
        print(f"âš ï¸ GCS ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--test", action="store_true", help="í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (5ê°œë§Œ ìƒì„±)")
    args = parser.parse_args()
    
    target_count = 5 if args.test else 3000
    
    samples = generate_all_samples(total=target_count, workers=10)
    
    if samples:
        train_path, valid_path = save_datasets(samples)
        if not args.test:
            upload_to_gcs(train_path, valid_path)
