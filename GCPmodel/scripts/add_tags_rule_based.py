#!/usr/bin/env python3
"""
ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ [ì‚¬ê³ ìœ ë„]/[ì‚¬ê³ ë¡œê·¸] íƒœê·¸ ì¶”ê°€
ì†Œí¬ë¼í‹± ëŒ€í™”ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•´ì„œ ìë™ìœ¼ë¡œ íƒœê·¸ ì‚½ì…
"""

import json
import re
from pathlib import Path
from typing import Dict
from tqdm import tqdm


class RuleBasedTagger:
    """ê·œì¹™ ê¸°ë°˜ íƒœê·¸ ì¶”ê°€"""

    def __init__(self):
        # ì§ˆë¬¸ íŒ¨í„´ (ì‚¬ê³ ìœ ë„ì— í•´ë‹¹)
        self.question_patterns = [
            r'\?',  # ë¬¼ìŒí‘œ
            r'~ì„ê¹Œìš”',
            r'~ì¸ê°€ìš”',
            r'~í• ê¹Œìš”',
            r'ìƒê°í•´.*ë´…ì‹œë‹¤',
            r'ê³ ë ¤í•´.*ë´…ì‹œë‹¤',
            r'ì£¼ëª©í•´.*ë´…ì‹œë‹¤',
            r'ì–´ë–¤.*ê¹Œìš”',
            r'ë¬´ì—‡.*ê¹Œìš”',
            r'ì™œ.*ê¹Œìš”',
        ]

        # ê´€ì°°/ë¶„ì„ íŒ¨í„´ (ì‚¬ê³ ë¡œê·¸ì— í•´ë‹¹)
        self.observation_patterns = [
            r'ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤',
            r'ì´í•´.*ìˆìŠµë‹ˆë‹¤',
            r'ì•Œ.*ìˆ.*ë‹ˆë‹¤',
            r'ë“œëŸ¬.*ë‹ˆë‹¤',
            r'ì£¼ëª©.*ì ',
            r'ì‹œì‘ì…ë‹ˆë‹¤',
            r'ì¢‹ì€.*ë‹ˆë‹¤',
            r'ì—°ê²°.*ë‹ˆë‹¤',
        ]

    def split_into_induction_and_log(self, text: str) -> tuple:
        """
        ì†Œí¬ë¼í‹± ëŒ€í™”ë¥¼ ì‚¬ê³ ìœ ë„ì™€ ì‚¬ê³ ë¡œê·¸ë¡œ ë¶„ë¦¬

        ì „ëµ:
        - ì•ë¶€ë¶„ 70%: ì‚¬ê³ ìœ ë„ (ì§ˆë¬¸ì´ ë§ì€ ë¶€ë¶„)
        - ë’·ë¶€ë¶„ 30%: ì‚¬ê³ ë¡œê·¸ (ê´€ì°°/ë¶„ì„ ë¶€ë¶„)

        Args:
            text: ì›ë³¸ ì†Œí¬ë¼í‹± ëŒ€í™”

        Returns:
            (ì‚¬ê³ ìœ ë„ ë¶€ë¶„, ì‚¬ê³ ë¡œê·¸ ë¶€ë¶„)
        """
        # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]

        if len(paragraphs) == 0:
            return (text, "í•™ìƒì˜ ì‚¬ê³  ê³¼ì •ì„ ê´€ì°°í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

        # ì „ì²´ ê¸¸ì´ì˜ 70%ë¥¼ ì‚¬ê³ ìœ ë„ë¡œ
        split_point = max(1, int(len(paragraphs) * 0.7))

        induction_parts = paragraphs[:split_point]
        log_parts = paragraphs[split_point:]

        # ì‚¬ê³ ë¡œê·¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ë¬¸ë‹¨ì„ ë¶„ì„ìœ¼ë¡œ ë³€í™˜
        if not log_parts:
            if induction_parts:
                last_para = induction_parts[-1]
                # ì§ˆë¬¸ì´ ë§ìœ¼ë©´ ì‚¬ê³ ë¡œê·¸ ìƒì„±
                if '?' in last_para or 'ê¹Œìš”' in last_para:
                    log_parts = ["ìœ„ì˜ ì§ˆë¬¸ë“¤ì„ í†µí•´ í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ê¹Šì´ ìƒê°í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤."]
                else:
                    log_parts = [last_para]
                    induction_parts = induction_parts[:-1]

        return ('\n\n'.join(induction_parts), '\n\n'.join(log_parts))

    def add_tags(self, text: str) -> str:
        """
        ì†Œí¬ë¼í‹± ëŒ€í™”ì— íƒœê·¸ ì¶”ê°€

        Args:
            text: ì›ë³¸ ì†Œí¬ë¼í‹± ëŒ€í™”

        Returns:
            íƒœê·¸ê°€ ì¶”ê°€ëœ í…ìŠ¤íŠ¸
        """
        # ì´ë¯¸ íƒœê·¸ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if '[ì‚¬ê³ ìœ ë„]' in text and '[ì‚¬ê³ ë¡œê·¸]' in text:
            return text

        # ì‚¬ê³ ìœ ë„ì™€ ì‚¬ê³ ë¡œê·¸ë¡œ ë¶„ë¦¬
        induction, log = self.split_into_induction_and_log(text)

        # íƒœê·¸ ì¶”ê°€
        tagged_text = ""

        if induction:
            tagged_text += "[ì‚¬ê³ ìœ ë„]\n" + induction

        if log:
            if tagged_text:
                tagged_text += "\n\n"
            tagged_text += "[ì‚¬ê³ ë¡œê·¸]\n" + log

        # ë‘˜ ë‹¤ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ ë°˜í™˜ (ì „ì²´ë¥¼ ì‚¬ê³ ìœ ë„ë¡œ)
        if not tagged_text.strip():
            tagged_text = "[ì‚¬ê³ ìœ ë„]\n" + text + "\n\n[ì‚¬ê³ ë¡œê·¸]\ní•™ìƒì˜ ì‚¬ê³  ê³¼ì •ì„ ê´€ì°° ì¤‘ì…ë‹ˆë‹¤."

        return tagged_text

    def convert_dataset(
        self,
        input_path: str,
        output_path: str,
        max_samples: int = None
    ):
        """
        ì „ì²´ ë°ì´í„°ì…‹ ë³€í™˜

        Args:
            input_path: ì…ë ¥ JSONL íŒŒì¼
            output_path: ì¶œë ¥ JSONL íŒŒì¼
            max_samples: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        """
        input_path = Path(input_path)
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        print(f"\n{'='*70}")
        print(f"ğŸ“ ê·œì¹™ ê¸°ë°˜ íƒœê·¸ ì¶”ê°€: {input_path.name}")
        print(f"{'='*70}")

        # ì…ë ¥ ë°ì´í„° ë¡œë“œ
        with open(input_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        if max_samples:
            lines = lines[:max_samples]

        print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(lines)}")

        # ë³€í™˜
        converted_count = 0
        error_count = 0

        with open(output_path, 'w', encoding='utf-8') as f:
            for i, line in enumerate(tqdm(lines, desc="íƒœê·¸ ì¶”ê°€ ì¤‘")):
                if not line.strip():
                    continue

                try:
                    item = json.loads(line)
                    original_output = item.get('output', '')

                    # íƒœê·¸ ì¶”ê°€
                    tagged_output = self.add_tags(original_output)

                    # ìƒˆ ì•„ì´í…œ ìƒì„±
                    new_item = item.copy()
                    new_item['output'] = tagged_output

                    # ì €ì¥
                    f.write(json.dumps(new_item, ensure_ascii=False) + '\n')
                    converted_count += 1

                except Exception as e:
                    print(f"\nâŒ ë¼ì¸ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    error_count += 1
                    f.write(line)

        print(f"\n{'='*70}")
        print(f"âœ… ë³€í™˜ ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {converted_count}")
        print(f"   ì‹¤íŒ¨: {error_count}")
        print(f"   ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"{'='*70}")

    def validate_output(self, output_path: str, sample_size: int = 5):
        """ë³€í™˜ëœ ë°ì´í„° ê²€ì¦"""
        print(f"\n{'='*70}")
        print(f"ğŸ” ë°ì´í„° ê²€ì¦: {Path(output_path).name}")
        print(f"{'='*70}")

        with open(output_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        total = len(lines)
        has_induction = 0
        has_log = 0
        has_both = 0

        for line in lines:
            if not line.strip():
                continue

            try:
                item = json.loads(line)
                output = item.get('output', '')

                has_ind = '[ì‚¬ê³ ìœ ë„]' in output
                has_l = '[ì‚¬ê³ ë¡œê·¸]' in output

                if has_ind:
                    has_induction += 1
                if has_l:
                    has_log += 1
                if has_ind and has_l:
                    has_both += 1

            except:
                pass

        print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
        print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {total}")
        print(f"   [ì‚¬ê³ ìœ ë„] íƒœê·¸: {has_induction} ({has_induction/total*100:.1f}%)")
        print(f"   [ì‚¬ê³ ë¡œê·¸] íƒœê·¸: {has_log} ({has_log/total*100:.1f}%)")
        print(f"   ë‘˜ ë‹¤ ìˆìŒ: {has_both} ({has_both/total*100:.1f}%)")

        # ìƒ˜í”Œ ì¶œë ¥
        print(f"\nğŸ“ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°:")
        print("-" * 70)

        for i, line in enumerate(lines[:sample_size]):
            if not line.strip():
                continue

            try:
                item = json.loads(line)
                output = item.get('output', '')

                print(f"\n[ìƒ˜í”Œ {i+1}]")
                print(f"Input: {item.get('input', '')[:60]}...")
                print(f"\nOutput:")
                print(output[:600])
                print("-" * 70)

            except:
                pass


def main():
    import argparse

    parser = argparse.ArgumentParser(description="ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ íƒœê·¸ ì¶”ê°€")

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="ì…ë ¥ JSONL íŒŒì¼"
    )
    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="ì¶œë ¥ JSONL íŒŒì¼"
    )
    parser.add_argument(
        "--max-samples",
        type=int,
        default=None,
        help="ìµœëŒ€ ë³€í™˜ ìƒ˜í”Œ ìˆ˜"
    )
    parser.add_argument(
        "--validate-only",
        action="store_true",
        help="ê²€ì¦ë§Œ ìˆ˜í–‰"
    )

    args = parser.parse_args()

    tagger = RuleBasedTagger()

    if not args.validate_only:
        # ë³€í™˜ ì‹¤í–‰
        tagger.convert_dataset(
            input_path=args.input,
            output_path=args.output,
            max_samples=args.max_samples
        )

    # ê²€ì¦
    if Path(args.output).exists():
        tagger.validate_output(args.output, sample_size=5)


if __name__ == "__main__":
    main()
